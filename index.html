<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Compiling NIR to FPGAs</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4.6.1/dist/reveal.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4.6.1/dist/theme/white.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4.6.1/plugin/highlight/monokai.css">

    <style>
        .column-wrapper {
            display: flex;
            gap: 2rem;
            align-items: stretch;
        }
        .column {
            flex: 1;
        }

        .ecosystem-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 2rem;
            margin: 2rem 0;
        }

        .platform-box {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 1rem;
            border-radius: 8px;
            text-align: center;
        }

        .timeline {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin: 2rem 0;
        }

        .timeline-item {
            text-align: center;
            flex: 1;
        }

        .timeline-arrow {
            font-size: 2rem;
            color: #667eea;
        }
		.credit {
			font-size: 50%;
		}
		.credit,
		.credit a {
			color: gray;
		}
    </style>
</head>

<!--
Structure:
* 14:20--14:30: (Setup)
* 14:30--14:40: Context (current pipelines, why they are not interoperable). Speaker: Michail
* 14:40--15:05: Introduction to NIR. Speaker: Jens
* 15:05--15:20: From NIR graphs to SpinalHDL abstractions. Speaker: Michail
* 15:20--15:30: FPGA mapping and core demos. Speaker: Michail

- Introduction to co-design for on-device learning

- Proposed Structure
    1. Context [10 min]
       - [1] Neuromorphic toolchains: what do they do?
       - [3] Top-down hardware design approaches
       - [3] Bottom-up hardware approaches
       - [3] Introduce co-design
    2. Introduction to NIR [25 min]
       - [3] Historical context: existing IRs
       - [5] NIR design principles
       - [5] NIR ODE primitives (example: breaking down LIF)
       - [5] Show graphs (nirviz)
       - [3] Existing platforms + future work
       - [2] Q&A
    3. NIR Compilation Flow [15 min]
       - [2] So let's say you want to make an FPGA accalerator...
       - [4] Why not use NIR's primitives as a component spec?
       - [4] NIR's graph serves as a good language
       - [4] Our toolchain & "Our hardware language" (SpinalHDL)
       - [1] BTW Spiker+ exists
    4. FPGA mapping demo [10 min]
       - [2] Pick sinabs, define Affine -> IF
       - [2] Show exporting to NIR & JSON
       - [1] Write a SpinalHDL main function creating an accelerator
       - [2] Compilation & traces
       - [3] Oops, it should have been 20 neurons (sinabs -> compile -> traces)
  -->

<body>
    <div class="reveal">
        <div class="slides">
            <section>
                <h1>Introduction to co-design <br /> for on-device learning</h1>
                <h4>Michail Rontionov, University of Southampton</h4>
                <h4>Jens E. Pedersen, Technical University of Denmark</h4>
            </section>
            <section>
              <h2>Agenda</h2>
              <ol style="font-size: 150%;">
                <li>Current neuromorphic toolchains</li>
                <li>The Neuromorphic Intermediate Representation (NIR)</li>
                <li>Motivating work: NIR &rarr; FPGA Compiler</li>
                <li>Compilation Demonstration</li>
              </ol>
            </section>
            <section>
                <section>
                    <h1>Current neuromorphic toolchains</h1>
                </section>
                <section>
                  <h2><u> Neuromorphic Toolchains: What do they do?</u> </h2>
                  <div style="height:0.5cm"></div>
                  <center>
                    <em>A neuromorphic toolchain describes the processes involved in transforming the idea of an algorithm to its execution on hardware.</em>
                  </center>
                  <div style="height:1.0cm"></div>

                  <div style="display: flex; gap: 2em; align-items: flex-start;">
                    <div style="flex: 1;">
                      <div style="text-align: left;">
                        <p class="fragment" data-fragment-index="2">Typically, they encode three important
                          parts:</p>
                        <ol style="margin-left: 0; padding-left: 2em;">
                          <li class="fragment" data-fragment-index="3">Network Conception and Simulation.</li>
                          <li class="fragment" data-fragment-index="4">Translation to Hardware Representation.
                          </li>
                          <li class="fragment" data-fragment-index="5">Hardware Execution.</li>
                        </ol>
                      </div>
                    </div>
                    <div
                      style="flex: 1; display: flex; flex-direction: row; align-items: center; justify-content: center;">
                      <img class="fragment" data-fragment-index="3" src="img/brain.svg" alt="Absrtract brain"
                           style="width: 50%; max-width: 300px;">
                      <span class="fragment" data-fragment-index="4"
                            style="font-size: 3em; margin: 0 10px;">&#8594;</span>
                      <img class="fragment" data-fragment-index="4" src="img/square.svg" alt="Square wave"
                           style="width: 50%; max-width: 300px;">
                      <span class="fragment" data-fragment-index="5"
                            style="font-size: 3em; margin: 0 10px;">&#8594;</span>
                      <img class="fragment" data-fragment-index="5" src="img/hardware.svg" alt="Hardware"
                           style="width: 50%; max-width: 300px;">
                    </div>
                </section>
                <section>
                    <h2><u> Network Simulators</u> </h2>
                    <div style="height:0.2cm"></div>
                    <p> The one you pick typically depends on where you're coming from. </p>
                    <div style="height:0.6cm"></div>
                    <div style="display: flex; gap: 2rem; align-items: stretch;">
                        <!-- Left column -->
                        <div class="fragment" data-fragment-index="1" style="flex: 1; text-align: center;">
                            <h4>Neuro-science</h4>
                            <img src="img/brian.png" alt="Image 1"
                                style="width: 100mm; max-width: 100%; height: auto; margin: 1rem auto; display: block;">
                            <img src="img/nengo.svg" alt="Image 2"
                                style="width: 100mm; max-width: 100%; height: auto; margin: 1rem auto; display: block;">
                        </div>

                        <!-- Dividing line -->
                        <div style="width: 2px; background: #ccc; margin: 0 1rem;"></div>

                        <!-- Right column -->
                        <div class="fragment" data-fragment-index="2" style="flex: 1; text-align: center;">
                            <h4>Machine Learning</h4>
                            <img src="img/sinabs.webp" alt="Image 1"
                                style="width: 100mm; max-width: 100%; height: auto; margin: 1rem auto; display: block;">
                            <img src="img/norse.png" alt="Image 1"
                                style="width: 100mm; max-width: 100%; height: auto; margin: 1rem auto; display: block;">
                            <img src="img/lava.png" alt="Image 1"
                                style="width: 100mm; max-width: 100%; height: auto; margin: 1rem auto; display: block;">
                            <img src="img/pynn.png" alt="Image 1"
                                style="width: 30mm; max-width: 100%; margin: 1rem auto; display: block;">
                        </div>
                    </div>
                </section>
                <section>
                  <h2><u> Hardware Representation</u> </h2>
                  <div style="height:0.2cm"></div>
                  <p> If your simulator was built for your hardware, you're in a good position. </p>
                  <!-- Row 1: Sinabs → Speck -->
                  <div style="display: flex; align-items: center; gap: 0rem; margin: 0.3rem 0;">
                    <div style="flex: 1; text-align: center;">
                      <img src="img/sinabs.webp" alt="Sinabs" style="width: auto; height: 40mm; max-height: 100%;">
                    </div>
                    <div style="font-size: 3rem; color: #666;">→</div>
                    <div style="flex: 1; text-align: center;">
                      <img src="img/speck.png" alt="Speck" style="width: auto; height: 70mm; max-height: 100%;">
                    </div>
                  </div>
                  <!-- Row 2: Lava → Loihi -->
                  <div style="display: flex; align-items: center; gap: 0rem; margin: 0.3rem 0;">
                    <div style="flex: 1; text-align: center;">
                      <img src="img/lava.png" alt="Lava" style="width: auto; height: 30mm; max-height: 100%;">
                    </div>
                    <div style="font-size: 3rem; color: #666;">→</div>
                    <div style="flex: 1; text-align: center;">
                      <img src="img/loihi.jpg" alt="Loihi" style="width: auto; height: 60mm; max-height: 100%;">
                    </div>
                  </div>
                  <!-- Row 3: PyNN → SpiNNaker -->
                  <div style="display: flex; align-items: center; gap: 0rem; margin: 0.3rem 0;">
                    <div style="flex: 1; text-align: center;">
                      <img src="img/pynn.png" alt="PyNN" style="width: auto;">
                    </div>
                    <div style="font-size: 3rem; color: #666;">→</div>
                    <div style="flex: 1; text-align: center;">
                      <img src="img/spinnaker.jpg" alt="SpiNNaker" style="width: auto; height: 60mm; max-height: 100%;">
                    </div>
                  </div>
                </section>
                <section>
                  <h2><u> Hardware Representation</u> </h2>
                  <div style="height:0.2cm"></div>
                  <p> But neuromorphics is a young field.</p>
                  <ul>
                    <li class="fragment"> What if your simulator or hardware doesn't support your model? </li>
                    <li class="fragment"> What if an iteration of your existing network isn't supported by your simulator or hardware? </li>
                    <li class="fragment"> What if your hardware doesn't have the representational accuracy required? </li>
                    <li class="fragment"> What if you no longer have access to the hardware and need to use something else? </li>
                    <li class="fragment"> How can you evaluate your algorithm across various hardware paradigms? </li>
                    <li class="fragment"> &hellip; </li>
                  </ul>
                  <div style="height:0.5cm"></div>
                  <p class="fragment"> You're stuck! Porting your code is costly and unreliable.
                </section>

                <section>
                  <h2><u> Why? </u> </h2>
                  <img src="img/fig.png" alt="paper" style="width: auto; height: 150mm; max-height: 100%;">
                  <p> Frenkel, Charlotte, David Bol, and Giacomo Indiveri. "Bottom-up and top-down approaches for the design of neuromorphic processing systems: Tradeoffs and synergies between natural and artificial intelligence." Proceedings of the IEEE 111.6 (2023): 623-652. </p>
                </section>

                <section>
                  <h2><u> Bottom-Up Hardware </u> </h2>
                  <div style="height:0.5cm"></div>
                  <p> Most common, at many different scales & types. </p>
                  <div style="display: flex; gap: 2rem; align-items: flex-start;">
                    <!-- Column 1 -->
                    <div class="fragment" data-fragment-index="1" style="flex: 1; text-align: center;">
                      <img src="img/memristor.png" alt="Image 1" style="width: 100%; max-width: 500px; height: 500px; object-fit: contain; margin-bottom: 0.5rem;">
                      <p style="font-size: 0.9em; margin: 0.5rem 0;">Analogue Memristor Arrays <br> (1024 synapses)</p>
                      <p style="font-size: 0.7em; color: #666; margin: 0;">Ongoing work at University of Southampton</p>
                    </div>

                    <!-- Dividing line 1 -->
                    <div style="width: 2px; background: #ccc;"></div>

                    <!-- Column 2 -->
                    <div class="fragment" data-fragment-index="2" style="flex: 1; text-align: center;">
                      <img src="img/odin.png" alt="Image 2" style="width: 100%; max-width: 500px; height: 500px; object-fit: contain; margin-bottom: 0.5rem;">
                      <p style="font-size: 0.9em; margin: 0.5rem 0;">ODIN on ASIC <br> (64k synapses, 256 neurons)</p>
                      <p style="font-size: 0.7em; color: #666; margin: 0;">Frenkel, Charlotte, et al. "A 0.086-mm&sup2; 12.7-pJ/SOP 64k-synapse 256-neuron online-learning digital spiking neuromorphic processor in 28-nm CMOS." IEEE transactions on biomedical circuits and systems 13.1 (2018): 145-158.</p>
                    </div>

                    <!-- Dividing line 2 -->
                    <div style="width: 2px; background: #ccc;"></div>

                    <!-- Column 3 -->
                    <div class="fragment" data-fragment-index="3" style="flex: 1; text-align: center;">
                      <img src="img/spinnbig.jpg" alt="Image 3" style="width: 100%; max-width: 700px; height: 500px; object-fit: contain; margin-bottom: 0.5rem;">
                      <p style="font-size: 0.9em; margin: 0.5rem 0;">SpiNNaker with ARM <br> (up to 1B neurons & 1T synapses)</p>
                      <p style="font-size: 0.7em; color: #666; margin: 0;">Furber, Steve B., et al. "The spinnaker project." Proceedings of the IEEE 102.5 (2014): 652-665.</p>
                    </div>
                  </div>
                </section>

                <section>
                  <h2><u> Top-Down </u> </h2>
                  <p> Dedicated & optimised to a specific algorithm. </p>
                  <div style="display: flex; gap: 2rem; align-items: flex-start;">
                    <!-- Column 1 -->
                    <div class="fragment" data-fragment-index="1" style="flex: 1; text-align: center;">
                      <img src="img/speck1.png" alt="Image 1" style="width: 100%; max-width: 500px; height: 500px; object-fit: contain; margin-bottom: 0.5rem;">                      <p style="font-size: 0.9em; margin: 0.5rem 0;">SPECK <br> Spiking CNN for Sinabs </p>
                      <p style="font-size: 0.6em; color: #666; margin: 0;">Richter, Ole, et al. "Speck: A smart event-based vision sensor with a low latency 327k neuron convolutional neuronal network processing pipeline." arXiv preprint arXiv:2304.06793 (2023).
</p>
                    </div>

                    <!-- Dividing line 1 -->
                    <div style="width: 2px; background: #ccc;"></div>

                    <div class="fragment" data-fragment-index="2" style="flex: 1; text-align: center;">
                      <img src="img/spoon.png" alt="Image 1" style="width: 100%; max-width: 500px; height: 500px; object-fit: contain; margin-bottom: 0.5rem;">                      <p style="font-size: 0.9em; margin: 0.5rem 0;">SPOON <br> Spiking CNN with RTDP Learning</p>
                      <p style="font-size: 0.6em; color: #666; margin: 0;">Frenkel, Charlotte, Jean-Didier Legat, and David Bol. "A 28-nm convolutional neuromorphic processor enabling online learning with spike-based retinas." 2020 IEEE International Symposium on Circuits and Systems (ISCAS). IEEE, 2020.</p>
                    </div>

                    <!-- Dividing line 2 -->
                    <div style="width: 2px; background: #ccc;"></div>


                    <div class="fragment" data-fragment-index="3" style="flex: 1; text-align: center;">
                      <img src="img/braindrop.png" alt="Image 1" style="width: 100%; max-width: 800px; height: 500px; object-fit: contain; margin-bottom: 0.5rem;">                      <p style="font-size: 0.9em; margin: 0.5rem 0;">BrainDrop <br> Mixed-Signal Neural Engineering Framework (NEF) Accelerator</p>
                      <p style="font-size: 0.6em; color: #666; margin: 0;">Neckar, Alexander, et al. "Braindrop: A mixed-signal neuromorphic architecture with a dynamical systems-based programming model." Proceedings of the IEEE 107.1 (2018): 144-164.</p>
                    </div>


                  </div>
                </section>
                <section>
                  With all this variety of backgrounds and paradigms, how could you unify the neuromorphic acceleration in the same way as ONNX has in machine learning?
                </section>
            </section>
            <section>
                <section>
                    <h2>Introduction to the <br />Neuromorphic Intermediate Representation</h2>
                    <img src="img/nir_logo.png" alt="NIR Logo" style="width: 500px; height: auto; margin-top: 1rem;">
                </section>
                <!-- Historical Context -->
                <section>
					<img src="img/how_to_scale.png" style="height: 20%;"/>
					<img src="img/missing_pieces.png" style="width: 100%;" class="fragment"/>
					<p class="credit">Kudithipudi et al., 2025</p>
                </section>

                <section>
                    <h2>The cost of fragmentation</h2>
                    <div class="benefit-grid">
                        <div class="benefit-card fragment">
                            <h4>⏱️ Research Velocity</h4>
                            <p>Months spent on platform-specific adaptations</p>
                        </div>
                        <div class="benefit-card fragment">
                            <h4>🔄 Reproducibility Crisis</h4>
                            <p>Studies can't be validated across platforms</p>
                        </div>
                        <div class="benefit-card fragment">
                            <h4>🚧 Innovation Barriers</h4>
                            <p>Hardware-software co-design slowed by incompatibility</p>
                        </div>
                    </div>
                </section>

                <section>
                    <h2>Not a new problem...</h2>
                    <ul>
                        <li class="fragment"> NeuroML (2001): Standardized models. Not widely
                            adopted for hardware implementations. </li>
                        <li class="fragment"> NineML (2008): Focused on biological realism but lacked hardware
                            abstraction. </li>
                        <li class="fragment"> PyNN (2009): Provided a common API for simulators but didn't address
                            hardware mapping. </li>
                    </ul>
                    <br /><br />
                    <h2 class="fragment">... if they can, we can too!</h2>
                    <img src="https://imgs.xkcd.com/comics/standards.png" alt="XKCD Standards"
                        style="width: 50%; height: auto; margin-top: 1rem;" class="fragment">
                </section>

                <!-- NIR Design Principles -->
                <section>
                    <h2>Really not a new problem</h2>
                    <div class="timeline fragment">
                        <div class="timeline-item">
                            <h4>1950s-60s</h4>
                            <p>CPU Fragmentation</p>
                            <small>IBM, CDC, Burroughs...</small>
                        </div>
                        <div class="timeline-arrow">→</div>
                        <div class="timeline-item">
                            <h4>1970s-80s</h4>
                            <p>Standardization</p>
                            <small>Common instruction sets (x86, RISC, ...)</small>
                        </div>
                        <div class="timeline-arrow">→</div>
                        <div class="timeline-item">
                            <h4>Today</h4>
                            <p>Portable Software</p>
                            <small>Write once, run anywhere</small>
                        </div>
                    </div>
                    <div class="timeline fragment">
                        <div class="timeline-item">
                            <h4>2010s</h4>
                            <p>ML Fragmentation</p>
                            <small>TensorFlow, PyTorch, Caffe, Theano...</small>
                        </div>
                        <div class="timeline-arrow">→</div>
                        <div class="timeline-item">
                            <h4>ONNX Era</h4>
                            <p>Standardization</p>
                            <small>Intermediate representations</small>
                        </div>
                        <div class="timeline-arrow">→</div>
                        <div class="timeline-item">
                            <h4>Today</h4>
                            <p>Seamless Deployment</p>
                            <small>Train anywhere, deploy everywhere</small>
                        </div>
                    </div>
                    <h2 class="fragment">Why did this work?</h2>
                </section>
				<section>
					<h3>Compiler correctness</h3>
					<img src="img/next_700.png"/ class="r-stretch">
					<p class="credit">Morris, 1973; Patterson and Adhmed, 2019</p>
					<div class="fragment">
						<img src="img/when_compute.png" />
						<p class="credit">"When does a physical system compute?", Horsman et al. 2014</p>
					</div>
				</section>
                <section>
                    <h2>NIR instruction axioms</h2>
                    <div class="column-wrapper">
                        <ol class="column" style="flex: 2;">
                            <li class="fragmentation">Computational primitives
                                <ul>
                                    <li class="fragment">Continuos-time ODEs <span class="fragment">(as opposed to discrete instructions)</span></li>
                                    <li class="fragment">Typed primitives <span class="fragment">(as opposed to random strings)</span></li>
                                    <li class="fragment">Composes <span class="fragment">(as opposed to textual descriptions)</span></li>
                                </ul>
                            </li>
                            <li class="fragment">Graph representation
                                <ul>
                                    <li>Nodes as primitives <span class="fragment">(as opposed to declarations)</span></li>
                                    <li>Edges as dataflow <span class="fragment">(as opposed to sequences)</span></li>
                                </ul>
                            </li>
                        </ol>
                        <div class="column">
                            <img src="img/nir_ir.svg" style="width: 50%;"/>
                        </div>
                    </div>
                </section>

                <!-- NIR ODE Primitives -->
                <section>
                  <h3>Reproducible computation</h3>
                  <h5 class="fragment" data-fragment-index="0">Neuron equations are based on <b>idealized</b>
                    continuous-time models</h5>

                  <p class="fragment" data-fragment-index="0">Leaky-integrator: &nbsp; $\dot{v} = (v_{leak} - v) + R
                    I$</p>
                  <img src="img/lif_comparison.svg" class="fragment" />
                </section>

                <section>
                    <h2>Composing and decomposing primitives</h2>
                    <p>$\text{LIF} = \text{LI} \circ \text{Spike} \circ \text{Reset}$</p>
                    <img src="img/lif_graph.svg">
                </section>

                <!-- Show graphs -->

                <section>
                  <h2>NIR in practice</h2>
                  <img src="img/norse_logo.png" style="height: 100px; margin:0; vertical-align: middle;" />
                  $\to$ SynSense Speck <img src="img/speck.png" style="height: 130px; margin:0 1em; vertical-align: middle;" />
                  <br />
                  <br />
                  <h4 class="fragment" data-fragment-index="0">Norse $\rightarrow$ NIR</h4>
                  <pre class="fragment" data-fragment-index="0"><code data-trim data-noescape data-line-numbers="1|3|5">import norse.torch as norse

model = norse.SequentialState( ... )

nir_model = norse.to_nir(model, torch.randn(1, 10))
        </code></pre>
          <h4 class="fragment">NIR $\rightarrow$ SynSense Sinabs</h4>
          <pre class="fragment"><code data-trim data-noescape data-line-numbers="1|3">import sinabs.from_nir

sinabs_model = sinabs.from_nir(nir_model, batch_size=4)
                </code></pre>

                  <br />
                </section>
                 <section>
                  <h2>Example graphs</h2>
                  <img src="img/cnn_graph.svg">
                  <img class="fragment" src="img/srnn_graph.svg">
                  <img class="fragment" src="img/nir_results.png" style="width: 100%; margin-top: 1rem;">
                 </section>

                <section data-background-color="white" data-transition="fade">
                  <h3>Not perfect!</h3>
                  <span class="fragment" data-fragment-index="0">Similarity for spiking CNN activity</span>
                  <div style="display: flex; justify-content: center; align-items: center;">
                    <img src="img/conv_similarity.png" style="width:70%;" data-fragment-index="0" class="fragment" />
                    <ul style="font-size: 90%; margin-left: 1.6em; width: 70%;">
                      <li class="fragment fade-in-then-semi-out">NIR reproduces ideal model</li>
                      <li class="fragment fade-in-then-semi-out" style="margin: 0.8em 0;">Exposes discretization
                        mismatch</li>
                      <li class="fragment fade-in-then-semi-out">Allows platform-specific optimization
                        <ul>
                          <li class="fragment fade-in-then-semi-out">Tailored integration</li>
                          <li class="fragment fade-in-then-semi-out">Quantization aware training</li>
                          <li class="fragment fade-in-then-semi-out">Post-training quantization</li>
                        </ul>
                      </li>
                    </ul>
                  </div>
                </section>
                 
                <!-- Existing Platforms + Future Work -->
                 <section>
                  <h2>Supported frameworks</h2>
                  <div class="column-wrapper">
                      <div class="column">
                        <h4>5 hardware platforms</h4>
                        BrainScales-2, Intel Loihi, SynSense Speck, SynSense Xylo, SpiNNaker2
                    </div>
                      <div class="column">
                        <h4>9 simulators</h4>
                      hxtorch, jaxsnn, Lava-DL, Nengo, Norse, Rockpool, Sinabs, snnTorch, Spyx
                      </div>
                  </div>
                  <p class="fragment">More in development...</p>
                  <img class="fragment" src="img/nir_platforms.png" style="width: 100%; margin-top: 1rem;">
                 </section>

                 <section>
                  <h2>Towards a neuromorphic compiler</h2>
                  <div class="fragment">
                    <p>NIR gives us:</p>
                    <ul>
                      <li class="fragment">Declarative and <i>typed</i> primitives</li>
                      <li class="fragment">Comparable computations across platforms</li>
                      <li class="fragment">Reproducible and transferrable results</li>
                    </ul>
                  </div>
                  <div class="fragment">
                    <p>Which enables:</p>
                    <ul>
                      <li class="fragment">Hardware-software co-design</li>
                      <li class="fragment">Cross-platform evaluation</li>
                      <li class="fragment">Rapid prototyping of neuromorphic hardware</li>
                    </ul>
                  </div>
                 </section>
            </section>
            <section>
              <section>
                <h2>Our work: NIR &rarr; FPGA Compiler</h2>
              </section>

              <section>
                <h2><u> So let's say you want to make an SNN accelerator.</u> </h2>
                <div style="height:0.5cm"></div>
                <ol>
                  <li class="fragment"> Most novel work on digital accelerators begins like this.
                  <li class="fragment"> You make architectural decisions you are interested and qualified to answer.
                  <li class="fragment"> Until you come to a nuanced decision,
                  <li class="fragment"> How would someone use this?
                    <ul>
                      <li class="fragment"> What neuron models am I supporting?
                      <li class="fragment"> What integration method am I using?
                      <li class="fragment"> What interconnectivity must it have?
                      <li class="fragment"> What simulator am I assuming?
                      <li class="fragment"> What problems does that simulator have?
                      <li class="fragment"> How am I going to compare this to another design?
                      <li class="fragment"> How am I verifying my design?
                      <li class="fragment"> ...
                    </ul>
                  <li class="fragment"> Huge barrier for hardware engineers.
                </ol>
              </section>
              <section>
                <h2><u> Why not just use NIR? </u> </h2>
                <div style="height:1cm"></div>
                <div style="display: flex; gap: 2em; align-items: flex-start;">
                  <div style="flex: 1;">
                    <div style="text-align: left;">
                      <ol style="margin-left: 0; padding-left: 2em;">
                        <li class="fragment" data-fragment-index="2"> Conventionally, you base your hardware on some discretization, and then hope your simulator's equations have a sufficient mapping.
                        <li class="fragment"> By basing your hardware off NIR, you get
                          <ul>
                            <li class="fragment"> Ready-made parameter format (weights, threshold, etc.).
                            <li class="fragment"> Specification of component computations (primitives).
                            <li class="fragment"> Specification of data flow (graph).
                            <li class="fragment"> Language to describe required and implemented functionality.
                            <li class="fragment"> Wide simulator support.
                          </ul>
                      </ol>
                    </div>
                  </div>
                  <div style="flex: 1; display: flex; flex-direction: row; align-items: center; justify-content: center; height: 100vh;">
                    <img  class="fragment" data-fragment-index="2" src="img/flow.svg" alt="" style="width: 1000px">
                  </div>
              </section>
              <section>
                <h2><u> The inside of a NIR file </u> </h2>
                <div style="height:0.5cm"></div>
                                <div style="display: flex; gap: 2em; align-items: flex-start;">
                  <div style="flex: 1;">
                    <div style="text-align: left;">
                      <ol style="margin-left: 0; padding-left: 2em;">
                        <li class="fragment"> Based on the Hirerachical Data Format v5 (HDF5) designed for supercomputing.
                        <li class="fragment"> "Nodes" specify the primitives and contain parameters <br>
                           <img  src="img/weights.png" alt="" style="height: 170px">
                        <li class="fragment"> "Edges" describe the graph in an adjacency list.
                          <img  src="img/edge.png" alt="" style="height: 170px"> </li>
                        <li class="fragment"> Ignoring all other advantages, it is a good ready-made format.
                      </ol>
                    </div>
                  </div>
                  <div style="flex: 1;">
                    Extract of a NIR file defining a spiking LeNet5
                    <img  src="img/nirfile.png" alt="" style="width: 70%">
                  </div>
              </section>
              <section>
                <h2><u> Using Primitives as a specification </u> </h2>
                <table style="font-size: 0.65em;">
                  <thead>
                    <tr>
                      <th>Primitive</th>
                      <th>Parameters</th>
                      <th>Computation</th>
                      <th>Reset</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr class="fragment" data-fragment-index="1">
                      <td><b>Integrator</b></td>
                      <td>\(R\)</td>
                      <td>\(\dot{v} = R I\)</td>
                      <td>-</td>
                    </tr>
                    <tr class="fragment" data-fragment-index="1">
                      <td><b>Threshold</b></td>
                      <td>\(\theta_\text{thr}\)</td>
                      <td>\(\delta(I - \theta_\text{thr})\)</td>
                      <td>-</td>
                    </tr>
                    <tr class="fragment" data-fragment-index="2">
                      <td><b>Integrate-and-fire</b></td>
                      <td>\(R, v_\text{reset}, v_\text{thr}\)</td>
                      <td><b>Integrator</b>; <b>Threshold</b></td>
                      <td>\(\begin{cases} v_\text{reset} & \text{Spike} \\ v & \text{else} \end{cases}\)</td>
                    </tr>
                    <tr class="fragment" data-fragment-index="3">
                      <td><b>Leaky integrator (LI)</b></td>
                      <td>\(\tau, R, v_\text{leak}\)</td>
                      <td>\(\tau \dot{v} = (v_\text{leak} - v) + R I\)</td>
                      <td>-</td>
                    </tr>
                    <tr class="fragment" data-fragment-index="4">
                      <td><b>Leaky integrate-fire (LIF)</b></td>
                      <td>\(\tau, R, v_\text{leak}, v_\text{reset}, v_\text{thr}\)</td>
                      <td><b>LI</b>; <b>Threshold</b></td>
                      <td>\(\begin{cases} v_\text{reset} & \text{Spike} \\ v & \text{else} \end{cases}\)</td>
                    </tr>
                    <tr class="fragment" data-fragment-index="5">
                      <td><b>Current-based leaky integrate-and-fire</b></td>
                      <td>\(\tau_\text{syn}, \tau_\text{mem}, R, v_\text{leak}, v_\text{reset}, v_\text{thr}, w_\text{in}\)</td>
                      <td><b>LI</b>; <b>Linear</b>; <b>LIF</b></td>
                      <td>\(\begin{cases} v_\text{reset} & \text{Spike} \\ v_\text{LIF} & \text{else} \end{cases}\)</td>
                    </tr>
                    <tr class="fragment" data-fragment-index="6">
                      <td><b>Linear</b></td>
                      <td>\(W\)</td>
                      <td>\(W I\)</td>
                      <td>-</td>
                    </tr>
                    <tr class="fragment" data-fragment-index="6">
                      <td><b>Affine</b></td>
                      <td>\(W, b\)</td>
                      <td>\(W \cdot I + b\)</td>
                      <td>-</td>
                    </tr>
                    <tr class="fragment" data-fragment-index="6">
                      <td><b>Convolution</b></td>
                      <td>\(W\), Stride, Padding, Dilation, Groups, Bias</td>
                      <td>\(f \star g\)</td>
                      <td>-</td>
                    </tr>
                  </tbody>
                </table>
              </section>
              <section>
                <h2><u> Using the graph to describe dataflow </u> </h2>
                <div style="height:0.5cm"></div>
                Typical execution graph, similar to the popular ONNX format in ML. <br>
                <div style="height:0.5cm"></div>
                <h4> Spiking LeNet5 in NIR's Graph </h4>
                <img  src="img/lenet5-1.svg" alt="" style="width: 50%">
              </section>
              <section>
                <h2><u> Using NIR to communicate hardware capabilities </u> </h2>
                <div style="height:0.5cm"></div>
                <div style="display: flex; gap: 2em; align-items: flex-start;">
                  <div style="flex: 1; display: flex; justify-content: center; align-items: center;">
                    <div style="text-align: left;">
                      <ol style="margin-left: 0; padding-left: 2em;">
                        <li class="fragment"> You now have freedom to determine how algorithmically flexible your hardware is.
                          <ul>
                            <li class="fragment"> One extreme is total flexibility, where you implement each primitive individually.
                            <li class="fragment"> The other is hardware efficiency, where you can specify that you implement an entire network only.
                          </ul>
                        <li class="fragment"> You can do this by specifying which NIR <strong>subgraphs</strong> your hardware supports, and can be communicated at the simulator's NIR export level.
                        <li class="fragment"> Both top-down and bottom-up approaches can be captured, <em>as long as they conform to NIR</em>.
                      </ol>
                    </div>
                  </div>
                  <div style="flex: 1;">
                  <div style="display: flex; align-items: center; gap: 1rem;">
                    <!-- Left bracket -->
                    <div style="font-size: 30rem; line-height: 0.5; color: #333;">{</div>

                    <!-- Images in rows -->
                    <div style="display: flex; flex-direction: column; gap: 0.5rem;">
                      <img src="img/nodes1.svg" alt="" style="height: 100px">
                      <img src="img/nodes2.svg" alt="" style="height: 100px">
                      <img src="img/nodes3.svg" alt="" style="height: 100px">
                      <img src="img/nodes4.svg" alt="" style="height: 100px">
                      <img src="img/nodes5.svg" alt="" style="height: 100px">
                    </div>

                    <!-- Right bracket -->
                    <div style="font-size: 30rem; line-height: 0.5; color: #333;">}</div>
                  </div>
                  </div>
              </section>
              <section>
                <h2><u>Addressing NIR's discretization problem</u></h2>
                <ol>
                  <li> Problem: NIR is defined with ODEs -- continuous space.
                  <li class="fragment"> This is future-proof for analog hardware (e.g. memristors, photonics).
                  <li class="fragment"> But our current digital hardware (such as FPGAs) are finite. We have to make a assumptions to compile a NIR graph to an FPGA.
                  <li class="fragment"> <em>Short-term</em> solution:
                    <ul>
                      <li> Just use an internal simulator.
                      <li> Provide an interface to discretization choices (e.g. integration method)
                      <li> Simulate the NIR graph in a simulator with those dicretizations.
                      <li> Record input/output values to verify the hardware.
                    </ul>
                  <li class="fragment"> <em>Long-term</em> solution:
                    <ul>
                      <li> Include either within the NIR graph or as external system.
                      <li> Future work.
                    </ul>
                </ol>
              </section>
            <section>
              <h2><u> Our Compiler and Toolchain </u> </h2>
              <img  src="img/new-toolchain.svg" alt="" style="width: 2000px">
            </section>
            </section>
            <section>
              <section>
                <h2>Compilation demonstration</h2>
                <div style="height:0.5cm"></div>
                <em>It's a work in progress, please excuse the roughness. </em>
              </section>
            </section>

            </div>
            </div>

            <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.6.1/dist/reveal.js"></script>
            <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.6.1/plugin/notes/notes.js"></script>
            <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.6.1/plugin/markdown/markdown.js"></script>
            <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.6.1/plugin/highlight/highlight.js"></script>
            <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.6.1/plugin/math/math.js"></script>
            <script>
              Reveal.initialize({
                  hash: true,
                  plugins: [RevealMarkdown, RevealHighlight, RevealNotes, RevealMath.KaTeX],
                  width: 1920,
                  height: 1080
              });
            </script>
</body>

</html>
